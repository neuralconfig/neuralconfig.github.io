<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenRouter Chat App | neuralconfig</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <nav class="nav-bar">
        <div class="nav-container">
            <a href="index.html" class="nav-logo">neural<span class="brackets">[</span>config<span class="brackets">]</span></a>
            <div class="nav-links">
                <a href="skills.html" class="nav-link">about</a>
                <a href="projects.html" class="nav-link">projects</a>
                <a href="https://github.com/neuralconfig" class="nav-link external">github</a>
            </div>
        </div>
    </nav>

    <div class="container">
        <div class="project-detail-header">
            <h1 class="project-detail-title">OpenRouter Chat App</h1>
            <div class="project-meta">
                <div class="project-meta-item">
                    <span class="brackets">[</span>Type<span class="brackets">]</span>: AI Integration
                </div>
                <div class="project-meta-item">
                    <span class="brackets">[</span>Language<span class="brackets">]</span>: Python
                </div>
                <div class="project-meta-item">
                    <span class="brackets">[</span>License<span class="brackets">]</span>: MIT
                </div>
            </div>
        </div>

        <section class="section">
            <h2 class="section-heading">Overview</h2>
            <p class="story-text">
                A streamlined AI chat interface that leverages OpenRouter's unified API to access multiple Large Language Model providers
                through a single endpoint. This project demonstrates practical implementation of LLM integration, focusing on creating
                a user-friendly interface while maintaining flexibility in model selection.
            </p>
            <p class="story-text">
                Built with a focus on simplicity and extensibility, this application serves as both a functional chat tool and a
                reference implementation for integrating various AI models into production applications.
            </p>
        </section>

        <section class="section">
            <h2 class="section-heading">Key Features</h2>
            <div class="feature-grid">
                <div class="feature-card">
                    <h3>Multi-Model Support</h3>
                    <p>Access GPT-4, Claude, Llama, and other models through a unified interface</p>
                </div>
                <div class="feature-card">
                    <h3>Stream Processing</h3>
                    <p>Real-time response streaming for improved user experience</p>
                </div>
                <div class="feature-card">
                    <h3>Context Management</h3>
                    <p>Intelligent conversation history handling with token optimization</p>
                </div>
                <div class="feature-card">
                    <h3>Error Handling</h3>
                    <p>Robust error management with graceful fallbacks and user feedback</p>
                </div>
            </div>
        </section>

        <section class="section">
            <h2 class="section-heading">Technical Implementation</h2>
            <p class="story-text">
                The application leverages asynchronous Python programming to handle real-time streaming responses from multiple LLM providers
                through OpenRouter's unified API. Key technical decisions include:
            </p>
            <ul class="feature-list">
                <li><strong>Async Architecture:</strong> Built on Python's asyncio for non-blocking I/O operations, enabling smooth streaming responses</li>
                <li><strong>HTTP Client:</strong> Uses HTTPX for modern async HTTP/2 support with connection pooling</li>
                <li><strong>SSE Parsing:</strong> Custom Server-Sent Events parser for handling streaming responses</li>
                <li><strong>Error Handling:</strong> Comprehensive exception handling with graceful fallbacks and user-friendly error messages</li>
                <li><strong>State Management:</strong> Efficient conversation history tracking with token count optimization</li>
            </ul>
            <p class="story-text">
                The modular design separates API interaction, UI rendering, and state management into distinct components,
                making the codebase maintainable and easily extensible for features like conversation persistence,
                multi-user support, and usage analytics.
            </p>
        </section>

        <section class="section">
            <h2 class="section-heading">Technology Stack</h2>
            <div class="tech-stack">
                <span class="tech-badge ai">Python 3.11+</span>
                <span class="tech-badge ai">AsyncIO</span>
                <span class="tech-badge ai">HTTPX</span>
                <span class="tech-badge ai">OpenRouter API</span>
                <span class="tech-badge ai">Streamlit</span>
            </div>
        </section>

        <section class="section">
            <h2 class="section-heading">AI Engineering Insights</h2>
            <p class="story-text">
                This project showcases several important concepts in AI systems engineering:
            </p>
            <ul class="feature-list">
                <li><strong>API Abstraction:</strong> Creating unified interfaces for diverse AI services</li>
                <li><strong>Stream Processing:</strong> Handling real-time data flows from LLMs</li>
                <li><strong>Token Management:</strong> Optimizing context windows for cost and performance</li>
                <li><strong>User Experience:</strong> Building responsive interfaces for AI interactions</li>
            </ul>
        </section>

        <div class="project-actions">
            <a href="https://github.com/neuralconfig/openrouter-chat-app" class="btn btn-primary">View on GitHub</a>
            <a href="projects.html" class="btn btn-secondary">Back to Projects</a>
        </div>
    </div>

    <footer class="footer">
        Â© 2025 NeuralConfig LLC | <a href="mailto:contact@neuralconfig.com">contact@neuralconfig.com</a>
    </footer>
    <script data-goatcounter="https://neuralconfig.goatcounter.com/count"
            async src="//gc.zgo.at/count.js"></script>
</body>
</html>
